{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note by me - the original code commented and I have re-written the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# The mathematical building blocks of neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## A first look at a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Loading the MNIST dataset in Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.datasets import mnist\n",
    "# (train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# train_images.shape\n",
    "\n",
    "# len(train_labels)\n",
    "\n",
    "# train_labels\n",
    "\n",
    "# test_images.shape\n",
    "\n",
    "# len(test_labels)\n",
    "\n",
    "# test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape\n",
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7b2a5b1950>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from PIL import Image\n",
    "img = Image.fromarray(train_images[0])\n",
    "# first way\n",
    "plt.imshow(img)\n",
    "\n",
    "# second way - not working. Need to debug later.\n",
    "# from IPython.display import display #, Image\n",
    "# from IPython.display import Image as ipy_Image\n",
    "\n",
    "# display( ipy_Image(img.resize(56,56,resample=Resampling.BICUBIC) ) ) # width=28, height=28) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check this for the various colormaps available -\n",
    "https://matplotlib.org/stable/gallery/color/colormap_reference.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7b2a188e90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img, cmap=plt.cm.binary)\n",
    "plt.imshow(img, cmap=plt.cm.binary_r)\n",
    "plt.imshow(img, cmap=plt.cm.Accent)\n",
    "plt.imshow(img, cmap=plt.cm.autumn)\n",
    "plt.imshow(img, cmap=plt.cm.winter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The network architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# model = keras.Sequential([\n",
    "#     layers.Dense(512, activation=\"relu\"),\n",
    "#     layers.Dense(10, activation=\"softmax\")\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1, 1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.tolist()[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(set(train_labels.tolist()).union(set(test_labels.tolist())) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-18 23:42:21.657320: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-18 23:42:22.009813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6138 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential( [\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax'),    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The compilation step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# model.compile(optimizer=\"rmsprop\",\n",
    "#               loss=\"sparse_categorical_crossentropy\",\n",
    "#               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Preparing the image data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# train_images = train_images.reshape((60000, 28 * 28))\n",
    "# train_images = train_images.astype(\"float32\") / 255\n",
    "# test_images = test_images.reshape((10000, 28 * 28))\n",
    "# test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape( (train_images.shape[0],-1) )\n",
    "test_images = test_images.reshape( (test_images.shape[0],-1) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**\"Fitting\" the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-18 23:42:22.206236: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "187/469 [==========>...................] - ETA: 0s - loss: 9.9513 - accuracy: 0.8636  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-18 23:42:22.798174: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 1s 807us/step - loss: 5.1875 - accuracy: 0.9042\n",
      "Epoch 2/2\n",
      "469/469 [==============================] - 0s 780us/step - loss: 0.7156 - accuracy: 0.9564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7b29d50610>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels,batch_size=128, epochs=2)\n",
    "# note that since the data size is very small, batch size of 65536 or 60000 also works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the model to make predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# test_digits = test_images[0:10]\n",
    "# predictions = model.predict(test_digits)\n",
    "# predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape\n",
    "pred = predictions.argmax(axis=1)\n",
    "pred.shape\n",
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  94.35\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"accuracy = \", 100*np.sum(pred == test_labels)/len(pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# predictions[0].argmax()\n",
    "\n",
    "# predictions[0][7]\n",
    "\n",
    "# test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Evaluating the model on new data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "# print(f\"test_acc: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that evaluate() returns the loss and accuracy automatically based on the loss and accuracy passed in the compile() func."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 576us/step - loss: 0.8532 - accuracy: 0.9435\n"
     ]
    }
   ],
   "source": [
    "test_results = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.853179395198822, 0.9434999823570251]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Data representations for neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Scalars (rank-0 tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# x = np.array(12)\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(12221213)\n",
    "x\n",
    "x.shape\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Vectors (rank-1 tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# x = np.array([12, 3, 6, 14, 7])\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([423425])\n",
    "y\n",
    "y.shape\n",
    "y.ndim\n",
    "\n",
    "z = np.array([1,2,3,4,5])\n",
    "z\n",
    "z.shape\n",
    "z.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Matrices (rank-2 tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# x = np.array([[5, 78, 2, 34, 0],\n",
    "#               [6, 79, 3, 35, 1],\n",
    "#               [7, 80, 4, 36, 2]])\n",
    "# x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "])\n",
    "x.shape\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Rank-3 and higher-rank tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# x = np.array([[[5, 78, 2, 34, 0],\n",
    "#                [6, 79, 3, 35, 1],\n",
    "#                [7, 80, 4, 36, 2]],\n",
    "#               [[5, 78, 2, 34, 0],\n",
    "#                [6, 79, 3, 35, 1],\n",
    "#                [7, 80, 4, 36, 2]],\n",
    "#               [[5, 78, 2, 34, 0],\n",
    "#                [6, 79, 3, 35, 1],\n",
    "#                [7, 80, 4, 36, 2]]])\n",
    "# x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([\n",
    "    [\n",
    "        [1,2,3],\n",
    "        [11,12,13],\n",
    "        [21,22,23],\n",
    "        [31,32,33]\n",
    "    ],\n",
    "    [\n",
    "        [4,5,6],\n",
    "        [14,15,16],\n",
    "        [24,25,26],\n",
    "        [34,35,36]\n",
    "    ]\n",
    "])\n",
    "# 2 x 4 x 3\n",
    "x.shape\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Key attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.datasets import mnist\n",
    "# (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# train_images.ndim\n",
    "\n",
    "# train_images.shape\n",
    "\n",
    "# train_images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load again to do some more operations on the original data\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Displaying the fourth digit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# digit = train_images[4]\n",
    "# plt.imshow(digit, cmap=plt.cm.binary )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# train_labels[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcLElEQVR4nO3de2zV9f3H8dfh0iNoe2qtvY0WC4hsIp1j0nUoQ+la6mIEyeJtCTiDEYsR0Wm6qFy2pD8xUYNhGHeBmQleEoF5GQsWW+IsbNxSmbOhpBs10KIsnFMKlIZ+fn8QzjwCwudwTt9teT6Sb0LP+b77/ey7kz79cg7fBpxzTgAA9LAB1gsAAFycCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADAxyHoBX9fd3a19+/YpNTVVgUDAejkAAE/OObW3tysvL08DBpz9OqfXBWjfvn3Kz8+3XgYA4AK1tLRo2LBhZ32+1wUoNTVV0smFp6WlGa8GAOArEokoPz8/+vP8bJIWoGXLlum5555Ta2urioqK9NJLL2nChAnnnDv1125paWkECAD6sHO9jZKUDyG88cYbmj9/vhYsWKDt27erqKhI5eXlOnDgQDIOBwDog5ISoOeff16zZ8/Wfffdp+985zt6+eWXNXToUP3hD39IxuEAAH1QwgN0/Phxbdu2TaWlpf87yIABKi0tVX19/Wn7d3Z2KhKJxGwAgP4v4QH68ssvdeLECWVnZ8c8np2drdbW1tP2r66uVigUim58Ag4ALg7m/xC1qqpK4XA4urW0tFgvCQDQAxL+KbjMzEwNHDhQbW1tMY+3tbUpJyfntP2DwaCCwWCilwEA6OUSfgWUkpKi8ePHq6amJvpYd3e3ampqVFJSkujDAQD6qKT8O6D58+dr5syZ+v73v68JEyboxRdfVEdHh+67775kHA4A0AclJUB33nmnvvjiCz3zzDNqbW3Vd7/7Xa1fv/60DyYAAC5eAeecs17EV0UiEYVCIYXDYe6EAAB90Pn+HDf/FBwA4OJEgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmBhkvQAA56e9vd175vDhw3Ed67333vOeOXDggPfMY4895j0TDAa9Z9A7cQUEADBBgAAAJhIeoIULFyoQCMRsY8aMSfRhAAB9XFLeA7r22mv1wQcf/O8gg3irCQAQKyllGDRokHJycpLxrQEA/URS3gPavXu38vLyNGLECN17773au3fvWfft7OxUJBKJ2QAA/V/CA1RcXKyVK1dq/fr1Wr58uZqbm3XTTTed9SOk1dXVCoVC0S0/Pz/RSwIA9EIJD1BFRYV++tOfaty4cSovL9f777+vQ4cO6c033zzj/lVVVQqHw9GtpaUl0UsCAPRCSf90QHp6ukaPHq2mpqYzPh8MBvmHZQBwEUr6vwM6fPiw9uzZo9zc3GQfCgDQhyQ8QI8//rjq6ur073//Wx9//LGmT5+ugQMH6u677070oQAAfVjC/wru888/1913362DBw/qyiuv1I033qjNmzfryiuvTPShAAB9WMID9Prrryf6WwK9WnNzs/fMkiVLvGfq6+u9Zz755BPvmZ7U2trqPbN06dIkrAQWuBccAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGAi6b+QDrDw2WefxTX34osves/86U9/8p45evSo94xzznumoKDAe0aSUlNTvWc+/fRT75mz/abkb/LQQw95z4wZM8Z7BsnHFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDds9KhwOOw98+STT3rPvPHGG94zkhSJROKa6wmjR4/2nvnrX/8a17GOHz/uPRPPHae/+OIL75kvv/zSewa9E1dAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJbkaKHrVmzRrvmd/+9rdJWImtUaNGec9s2LDBeyY/P997RpJ2794d1xzggysgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAENyNFj3rzzTetl/CNrrrqKu+ZCRMmeM88++yz3jPx3lg0Hp999lmPHQsXL66AAAAmCBAAwIR3gDZt2qTbbrtNeXl5CgQCWrt2bczzzjk988wzys3N1ZAhQ1RaWsrvFgEAnMY7QB0dHSoqKtKyZcvO+PySJUu0dOlSvfzyy9qyZYsuvfRSlZeX69ixYxe8WABA/+H9IYSKigpVVFSc8TnnnF588UU99dRTuv322yVJr776qrKzs7V27VrdddddF7ZaAEC/kdD3gJqbm9Xa2qrS0tLoY6FQSMXFxaqvrz/jTGdnpyKRSMwGAOj/Ehqg1tZWSVJ2dnbM49nZ2dHnvq66ulqhUCi69eRHTQEAdsw/BVdVVaVwOBzdWlparJcEAOgBCQ1QTk6OJKmtrS3m8ba2tuhzXxcMBpWWlhazAQD6v4QGqLCwUDk5OaqpqYk+FolEtGXLFpWUlCTyUACAPs77U3CHDx9WU1NT9Ovm5mbt3LlTGRkZKigo0Lx58/TrX/9aV199tQoLC/X0008rLy9P06ZNS+S6AQB9nHeAtm7dqptvvjn69fz58yVJM2fO1MqVK/XEE0+oo6NDDzzwgA4dOqQbb7xR69ev1yWXXJK4VQMA+jzvAE2ePFnOubM+HwgEtHjxYi1evPiCFob+6Xe/+533zCuvvOI9U1ZW5j0jSaNGjfKeycrKiutYvdnX38cFksH8U3AAgIsTAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHjfDRu4EHl5ed4zCxcuTPxC8I0+/vhj6yXgIsAVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRAhdo6dKl3jMdHR3eM84575lAIOA9I0m7du2Ka87XxIkTvWdKSkqSsBJY4AoIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDBzUjR6x05csR75p///Gdcx1q8eLH3zHvvvRfXsXz15M1I45GXl+c9s2LFCu+ZgQMHes+gd+IKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwc1IEbeuri7vmR07dnjPzJgxw3tm37593jOSNHToUO+ZeG7C+cMf/tB7Zv369d4zHR0d3jPxOnHihPfM22+/7T3zyCOPeM+kpKR4zyD5uAICAJggQAAAE94B2rRpk2677Tbl5eUpEAho7dq1Mc/PmjVLgUAgZps6dWqi1gsA6Ce8A9TR0aGioiItW7bsrPtMnTpV+/fvj26rV6++oEUCAPof7w8hVFRUqKKi4hv3CQaDysnJiXtRAID+LynvAdXW1iorK0vXXHON5syZo4MHD551387OTkUikZgNAND/JTxAU6dO1auvvqqamho9++yzqqurU0VFxVk/olldXa1QKBTd8vPzE70kAEAvlPB/B3TXXXdF/3zddddp3LhxGjlypGprazVlypTT9q+qqtL8+fOjX0ciESIEABeBpH8Me8SIEcrMzFRTU9MZnw8Gg0pLS4vZAAD9X9ID9Pnnn+vgwYPKzc1N9qEAAH2I91/BHT58OOZqprm5WTt37lRGRoYyMjK0aNEizZgxQzk5OdqzZ4+eeOIJjRo1SuXl5QldOACgb/MO0NatW3XzzTdHvz71/s3MmTO1fPlyNTQ06I9//KMOHTqkvLw8lZWV6Ve/+pWCwWDiVg0A6PMCzjlnvYivikQiCoVCCofDvB/UQ44fPx7XXDw3x5w+fXpcx/K1cOHCuOa++h9X5+vGG2/0nvnvf//rPXPLLbd4z3zyySfeM73dqlWrvGemTZsW17H4D+f4nO/Pce4FBwAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMJ/5XcsNXV1eU9s2DBgriOtWTJkrjmfFVUVHjPPPzww3EdKz093Xvmiy++8J659dZbvWcaGhq8Z+K9m/MTTzzhPRPPnbfXrVvnPXPPPfd4z/z4xz/2npHiOw+XX355XMfydf311/fIcZKJKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQ3I+3FTpw44T3z9NNPe88899xz3jOSdNlll3nPVFdXe8/cfffd3jPx3FRUkv7xj394z8Rz49Pt27d7z4wePdp7Zvny5d4zknTzzTd7z0QiEe+Zjz/+2Hvmtdde857585//7D0jxX8TU18FBQXeM83NzUlYSc/iCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMBFwzjnrRXxVJBJRKBRSOBxWWlqa9XJMxXMjyblz53rPXHrppd4zkvTKK694z5SVlXnPbNmyxXtmxYoV3jOS9P7773vPHD161HtmwYIF3jP33Xef90x+fr73TH+0evXquObiufFpPF544QXvmauvvjoJK0mM8/05zhUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCm5H2Yrm5ud4zBw4c8J4JBoPeM5I0ZswY75kjR454z+zevdt7pictWrTIe6aqqsp7ZuDAgd4zgAVuRgoA6NUIEADAhFeAqqurdcMNNyg1NVVZWVmaNm2aGhsbY/Y5duyYKisrdcUVV+iyyy7TjBkz1NbWltBFAwD6Pq8A1dXVqbKyUps3b9aGDRvU1dWlsrIydXR0RPd59NFH9c477+itt95SXV2d9u3bpzvuuCPhCwcA9G2DfHZev359zNcrV65UVlaWtm3bpkmTJikcDuv3v/+9Vq1apVtuuUXSyd9M+e1vf1ubN2/WD37wg8StHADQp13Qe0DhcFiSlJGRIUnatm2burq6VFpaGt1nzJgxKigoUH19/Rm/R2dnpyKRSMwGAOj/4g5Qd3e35s2bp4kTJ2rs2LGSpNbWVqWkpCg9PT1m3+zsbLW2tp7x+1RXVysUCkU3foc9AFwc4g5QZWWldu3apddff/2CFlBVVaVwOBzdWlpaLuj7AQD6Bq/3gE6ZO3eu3n33XW3atEnDhg2LPp6Tk6Pjx4/r0KFDMVdBbW1tysnJOeP3CgaDcf9DSABA3+V1BeSc09y5c7VmzRpt3LhRhYWFMc+PHz9egwcPVk1NTfSxxsZG7d27VyUlJYlZMQCgX/C6AqqsrNSqVau0bt06paamRt/XCYVCGjJkiEKhkO6//37Nnz9fGRkZSktL08MPP6ySkhI+AQcAiOEVoOXLl0uSJk+eHPP4ihUrNGvWLEnSCy+8oAEDBmjGjBnq7OxUeXm5fvOb3yRksQCA/oObkfZi119/vfdMQ0NDElZi6yc/+Yn3zKRJk+I61rRp07xnrrrqKu+ZQYPievsV6BO4GSkAoFcjQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW7J24tt2rTJe2bt2rXeM9u3b/eekaSsrCzvmZ///OfeM5dffrn3TEpKivcMgJ7FFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYCLgnHPWi/iqSCSiUCikcDistLQ06+UAADyd789xroAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE14Bqq6u1g033KDU1FRlZWVp2rRpamxsjNln8uTJCgQCMduDDz6Y0EUDAPo+rwDV1dWpsrJSmzdv1oYNG9TV1aWysjJ1dHTE7Dd79mzt378/ui1ZsiShiwYA9H2DfHZev359zNcrV65UVlaWtm3bpkmTJkUfHzp0qHJychKzQgBAv3RB7wGFw2FJUkZGRszjr732mjIzMzV27FhVVVXpyJEjZ/0enZ2dikQiMRsAoP/zugL6qu7ubs2bN08TJ07U2LFjo4/fc889Gj58uPLy8tTQ0KAnn3xSjY2Nevvtt8/4faqrq7Vo0aJ4lwEA6KMCzjkXz+CcOXP0l7/8RR999JGGDRt21v02btyoKVOmqKmpSSNHjjzt+c7OTnV2dka/jkQiys/PVzgcVlpaWjxLAwAYikQiCoVC5/w5HtcV0Ny5c/Xuu+9q06ZN3xgfSSouLpakswYoGAwqGAzGswwAQB/mFSDnnB5++GGtWbNGtbW1KiwsPOfMzp07JUm5ublxLRAA0D95BaiyslKrVq3SunXrlJqaqtbWVklSKBTSkCFDtGfPHq1atUq33nqrrrjiCjU0NOjRRx/VpEmTNG7cuKT8DwAA9E1e7wEFAoEzPr5ixQrNmjVLLS0t+tnPfqZdu3apo6ND+fn5mj59up566qnzfj/nfP/uEADQOyXlPaBztSo/P191dXU+3xIAcJHiXnAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABODrBfwdc45SVIkEjFeCQAgHqd+fp/6eX42vS5A7e3tkqT8/HzjlQAALkR7e7tCodBZnw+4cyWqh3V3d2vfvn1KTU1VIBCIeS4SiSg/P18tLS1KS0szWqE9zsNJnIeTOA8ncR5O6g3nwTmn9vZ25eXlacCAs7/T0+uugAYMGKBhw4Z94z5paWkX9QvsFM7DSZyHkzgPJ3EeTrI+D9905XMKH0IAAJggQAAAE30qQMFgUAsWLFAwGLReiinOw0mch5M4DydxHk7qS+eh130IAQBwcehTV0AAgP6DAAEATBAgAIAJAgQAMNFnArRs2TJdddVVuuSSS1RcXKy///3v1kvqcQsXLlQgEIjZxowZY72spNu0aZNuu+025eXlKRAIaO3atTHPO+f0zDPPKDc3V0OGDFFpaal2795ts9gkOtd5mDVr1mmvj6lTp9osNkmqq6t1ww03KDU1VVlZWZo2bZoaGxtj9jl27JgqKyt1xRVX6LLLLtOMGTPU1tZmtOLkOJ/zMHny5NNeDw8++KDRis+sTwTojTfe0Pz587VgwQJt375dRUVFKi8v14EDB6yX1uOuvfZa7d+/P7p99NFH1ktKuo6ODhUVFWnZsmVnfH7JkiVaunSpXn75ZW3ZskWXXnqpysvLdezYsR5eaXKd6zxI0tSpU2NeH6tXr+7BFSZfXV2dKisrtXnzZm3YsEFdXV0qKytTR0dHdJ9HH31U77zzjt566y3V1dVp3759uuOOOwxXnXjncx4kafbs2TGvhyVLlhit+CxcHzBhwgRXWVkZ/frEiRMuLy/PVVdXG66q5y1YsMAVFRVZL8OUJLdmzZro193d3S4nJ8c999xz0ccOHTrkgsGgW716tcEKe8bXz4Nzzs2cOdPdfvvtJuuxcuDAASfJ1dXVOedO/n8/ePBg99Zbb0X3+de//uUkufr6eqtlJt3Xz4Nzzv3oRz9yjzzyiN2izkOvvwI6fvy4tm3bptLS0uhjAwYMUGlpqerr6w1XZmP37t3Ky8vTiBEjdO+992rv3r3WSzLV3Nys1tbWmNdHKBRScXHxRfn6qK2tVVZWlq655hrNmTNHBw8etF5SUoXDYUlSRkaGJGnbtm3q6uqKeT2MGTNGBQUF/fr18PXzcMprr72mzMxMjR07VlVVVTpy5IjF8s6q192M9Ou+/PJLnThxQtnZ2TGPZ2dn67PPPjNalY3i4mKtXLlS11xzjfbv369Fixbppptu0q5du5Sammq9PBOtra2SdMbXx6nnLhZTp07VHXfcocLCQu3Zs0e//OUvVVFRofr6eg0cONB6eQnX3d2tefPmaeLEiRo7dqykk6+HlJQUpaenx+zbn18PZzoPknTPPfdo+PDhysvLU0NDg5588kk1Njbq7bffNlxtrF4fIPxPRUVF9M/jxo1TcXGxhg8frjfffFP333+/4crQG9x1113RP1933XUaN26cRo4cqdraWk2ZMsVwZclRWVmpXbt2XRTvg36Ts52HBx54IPrn6667Trm5uZoyZYr27NmjkSNH9vQyz6jX/xVcZmamBg4ceNqnWNra2pSTk2O0qt4hPT1do0ePVlNTk/VSzJx6DfD6ON2IESOUmZnZL18fc+fO1bvvvqsPP/ww5te35OTk6Pjx4zp06FDM/v319XC283AmxcXFktSrXg+9PkApKSkaP368ampqoo91d3erpqZGJSUlhiuzd/jwYe3Zs0e5ubnWSzFTWFionJycmNdHJBLRli1bLvrXx+eff66DBw/2q9eHc05z587VmjVrtHHjRhUWFsY8P378eA0ePDjm9dDY2Ki9e/f2q9fDuc7DmezcuVOSetfrwfpTEOfj9ddfd8Fg0K1cudJ9+umn7oEHHnDp6emutbXVemk96rHHHnO1tbWuubnZ/e1vf3OlpaUuMzPTHThwwHppSdXe3u527NjhduzY4SS5559/3u3YscP95z//cc4593//938uPT3drVu3zjU0NLjbb7/dFRYWuqNHjxqvPLG+6Ty0t7e7xx9/3NXX17vm5mb3wQcfuO9973vu6quvdseOHbNeesLMmTPHhUIhV1tb6/bv3x/djhw5Et3nwQcfdAUFBW7jxo1u69atrqSkxJWUlBiuOvHOdR6amprc4sWL3datW11zc7Nbt26dGzFihJs0aZLxymP1iQA559xLL73kCgoKXEpKipswYYLbvHmz9ZJ63J133ulyc3NdSkqK+9a3vuXuvPNO19TUZL2spPvwww+dpNO2mTNnOudOfhT76aefdtnZ2S4YDLopU6a4xsZG20UnwTedhyNHjriysjJ35ZVXusGDB7vhw4e72bNn97v/SDvT/35JbsWKFdF9jh496h566CF3+eWXu6FDh7rp06e7/fv32y06Cc51Hvbu3esmTZrkMjIyXDAYdKNGjXK/+MUvXDgctl341/DrGAAAJnr9e0AAgP6JAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDx//EfI1R7+BZ4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = train_images[5]\n",
    "\n",
    "plt.imshow(digit, cmap=plt.cm.binary )\n",
    "print(train_labels[5])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Manipulating tensors in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, :, :]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "my_slice = train_images[:, 14:, 14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "my_slice = train_images[:, 7:-7, 7:-7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The notion of data batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "batch = train_images[:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "batch = train_images[128:256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "n = 3\n",
    "batch = train_images[128 * n:128 * (n + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Real-world examples of data tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Vector data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Timeseries data or sequence data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Video data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## The gears of neural networks: tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Element-wise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "max(iterable, *[, default=obj, key=func]) -> value\n",
       "max(arg1, arg2, *args, *[, key=func]) -> value\n",
       "\n",
       "With a single iterable argument, return its biggest item. The\n",
       "default keyword-only argument specifies an object to return if\n",
       "the provided iterable is empty.\n",
       "With two or more arguments, return the largest argument.\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# def naive_relu(x):\n",
    "#     assert len(x.shape) == 2\n",
    "#     x = x.copy()\n",
    "#     for i in range(x.shape[0]):\n",
    "#         for j in range(x.shape[1]):\n",
    "#             x[i, j] = max(x[i, j], 0)\n",
    "#     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i,j] = np.max(x[i,j],0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mnaive_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_51983/56559502.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "naive_relu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# def naive_add(x, y):\n",
    "#     assert len(x.shape) == 2\n",
    "#     assert x.shape == y.shape\n",
    "#     x = x.copy()\n",
    "#     for i in range(x.shape[0]):\n",
    "#         for j in range(x.shape[1]):\n",
    "#             x[i, j] += y[i, j]\n",
    "#     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add(x, y):\n",
    "    assert x.shape == y.shape\n",
    "    assert len(x.shape) == 2\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i,j] = x[i,j] + y[i,j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 0.00 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "x = np.random.random((20, 100))\n",
    "y = np.random.random((20, 100))\n",
    "\n",
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = x + y\n",
    "    z = np.maximum(z, 0.)\n",
    "print(\"Took: {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken =  0.011595010757446289\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "x = np.random.random((10,50))\n",
    "y = np.random.random((10,50))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for loop in range(10000):\n",
    "    z = x + y\n",
    "    z = np.maximum(z,0.)\n",
    "print(\"time taken = \", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# t0 = time.time()\n",
    "# for _ in range(1000):\n",
    "#     z = naive_add(x, y)\n",
    "#     z = naive_relu(z)\n",
    "# print(\"Took: {0:.2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken =  15.66649603843689\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for loop in range(10000):\n",
    "    z = naive_add(x,y)\n",
    "    z = naive_relu(z)\n",
    "print(\"time taken = \", time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# X = np.random.random((32, 10))\n",
    "# y = np.random.random((10,))\n",
    "# y = np.expand_dims(y, axis=0)\n",
    "y = np.concatenate([y] * 32, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random((20,50))\n",
    "y = np.random.random(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.expand_dims(y,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "y_concat = np.concatenate([y]*20,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# def naive_add_matrix_and_vector(x, y):\n",
    "#     assert len(x.shape) == 2\n",
    "#     assert len(y.shape) == 1\n",
    "#     assert x.shape[1] == y.shape[0]\n",
    "#     x = x.copy()\n",
    "#     for i in range(x.shape[0]):\n",
    "#         for j in range(x.shape[1]):\n",
    "#             x[i, j] += y[j]\n",
    "#     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add_mat_vec(x,y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert ( (x.shape[0] == y.shape[0]) | (x.shape[1] == y.shape[0]) )\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            if x.shape[1] == y.shape[0]:\n",
    "                x[i,j] += y[j]\n",
    "            else:\n",
    "                x[i,j] += y[i]\n",
    "    return x                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.random.random((64, 3, 32, 10))\n",
    "y = np.random.random((32, 10))\n",
    "z = np.maximum(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Tensor product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "x = np.random.random((32,))\n",
    "y = np.random.random((32,))\n",
    "z = np.dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_vector_dot(x, y):\n",
    "    assert len(x.shape) == 1\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    z = 0.\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i] += x[i, j] * y[j]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        z[i] = naive_vector_dot(x[i, :], y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def naive_matrix_dot(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 2\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    z = np.zeros((x.shape[0], y.shape[1]))\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            row_x = x[i, :]\n",
    "            column_y = y[:, j]\n",
    "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Tensor reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[0., 1.],\n",
    "             [2., 3.],\n",
    "             [4., 5.]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [5.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((6, 1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 300)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros((300, 20))\n",
    "x = np.transpose(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Geometric interpretation of tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### A geometric interpretation of deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## The engine of neural networks: gradient-based optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### What's a derivative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Derivative of a tensor operation: the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Chaining derivatives: The Backpropagation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The chain rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Automatic differentiation with computation graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The gradient tape in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# x = tf.Variable(0.)\n",
    "# with tf.GradientTape() as tape:\n",
    "#     y = 2 * x + 3\n",
    "# grad_of_y_wrt_x = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.Variable(15.)\n",
    "y = tf.Variable(3.4)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2.5*x + 43\n",
    "y_grad_wrt_x = tape.gradient(y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.5>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_grad_wrt_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Added by me - Note -this gives an error - stating \"A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_grad_wrt_y = tape.gradient(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# x = tf.Variable(tf.random.uniform((2, 2)))\n",
    "# with tf.GradientTape() as tape:\n",
    "#     y = 2 * x + 3\n",
    "# grad_of_y_wrt_x = tape.gradient(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2.3, 2.3],\n",
       "       [2.3, 2.3]], dtype=float32)>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(tf.random.uniform((2,2)))\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2.3*x + 17\n",
    "y_grad_wrt_x = tape.gradient(y,x)\n",
    "y_grad_wrt_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random.uniform((2, 2)))\n",
    "b = tf.Variable(tf.zeros((2,)))\n",
    "x = tf.random.uniform((2, 2))\n",
    "with tf.GradientTape() as tape:\n",
    "    y = tf.matmul(x, W) + b\n",
    "grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[0.91967773, 0.91967773],\n",
       "        [1.1431885 , 1.1431885 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 2.], dtype=float32)>]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_of_y_wrt_W_and_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.5871979 , 0.14249718],\n",
       "       [0.422835  , 0.98867226]], dtype=float32)>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.uniform((2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[1.3994141, 0.8654785],\n",
       "        [1.3994141, 0.8654785]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 2.], dtype=float32)>]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = tf.Variable(tf.random.uniform((2,2)))\n",
    "b = tf.Variable(tf.zeros(2,))\n",
    "x = tf.random.uniform((2,2))\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = tf.matmul(w,x) + b\n",
    "dy_dx = tape.gradient(y,[w,b])\n",
    "dy_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.7493285 , 0.64987457],\n",
       "       [0.50551546, 0.36007297]], dtype=float32)>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8655884"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0].numpy() + x[0,1].numpy()\n",
    "x[1,0].numpy() + x[1,1].numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Added by me - vvvvImp & Good - </br> How the derivative is calculated -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.7493285 , 0.64987457],\n",
       "       [0.50551546, 0.36007297]], dtype=float32)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw00 = np.array( [ [1, 0],\n",
    "              [0, 0] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7493285 , 0.64987457],\n",
       "       [0.50551546, 0.36007297]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw00\n",
    "dw00[0,0]\n",
    "dw00.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.7493285, 0.       ],\n",
       "       [0.       , 0.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw00*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy_dw00 = tf.math.reduce_sum(tf.matmul(tf.Variable(1.*dw00), x.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=1.3992030620574951>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dy_dw00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Looking back at our first example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "# train_images = train_images.reshape((60000, 28 * 28))\n",
    "# train_images = train_images.astype(\"float32\") / 255\n",
    "# test_images = test_images.reshape((10000, 28 * 28))\n",
    "# test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape(train_images.shape[0], train_images.shape[1]*train_images.shape[2])\n",
    "train_images = train_images.astype(\"float32\")/255.\n",
    "test_images = test_images.reshape(test_images.shape[0], test_images.shape[1]*test_images.shape[2])\n",
    "test_images = test_images.astype(\"float32\")/255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# model = keras.Sequential([\n",
    "#     layers.Dense(512, activation=\"relu\"),\n",
    "#     layers.Dense(10, activation=\"softmax\")\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential( [\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# model.compile(optimizer=\"rmsprop\",\n",
    "#               loss=\"sparse_categorical_crossentropy\",\n",
    "#               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', metrics=['accuracy'], loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.3718 - accuracy: 0.8982\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1686 - accuracy: 0.9517\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.1188 - accuracy: 0.9664\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0904 - accuracy: 0.9739\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0726 - accuracy: 0.9791\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0580 - accuracy: 0.9835\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0476 - accuracy: 0.9868\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0401 - accuracy: 0.9891\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0329 - accuracy: 0.9914\n",
      "Epoch 10/10\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.0285 - accuracy: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7b2990be90>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, batch_size=256, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Reimplementing our first example from scratch in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple Dense class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# class NaiveDense:\n",
    "#     def __init__(self, input_size, output_size, activation):\n",
    "#         self.activation = activation\n",
    "\n",
    "#         w_shape = (input_size, output_size)\n",
    "#         w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
    "#         self.W = tf.Variable(w_initial_value)\n",
    "\n",
    "#         b_shape = (output_size,)\n",
    "#         b_initial_value = tf.zeros(b_shape)\n",
    "#         self.b = tf.Variable(b_initial_value)\n",
    "\n",
    "#     def __call__(self, inputs):\n",
    "#         return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
    "\n",
    "#     @property\n",
    "#     def weights(self):\n",
    "#         return [self.W, self.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((256,),)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note - comma needs to be added at the end of single channel tuple or provide list instead\n",
    "tf.random.uniform((256,), minval=1e-4, maxval=1e-1)\n",
    "tf.random.uniform([256], minval=1e-4, maxval=1e-1)\n",
    "(256,)\n",
    "((256,),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveDense:\n",
    "    def __init__(self, input_nodes, output_nodes=256, activation=tf.nn.relu):\n",
    "        self.activation = activation\n",
    "         \n",
    "        self.w = tf.Variable( tf.random.uniform( (input_nodes, output_nodes), minval=1e-4, maxval=1e-1) )\n",
    "        self.b = tf.Variable( tf.random.uniform((output_nodes,), minval=1e-4, maxval=1e-1))\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return self.activation( tf.matmul(x, self.w) + self.b )\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [self.w, self.b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple Sequential class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# class NaiveSequential:\n",
    "#     def __init__(self, layers):\n",
    "#         self.layers = layers\n",
    "\n",
    "#     def __call__(self, inputs):\n",
    "#         x = inputs\n",
    "#         for layer in self.layers:\n",
    "#            x = layer(x)\n",
    "#         return x\n",
    "\n",
    "#     @property\n",
    "#     def weights(self):\n",
    "#        weights = []\n",
    "#        for layer in self.layers:\n",
    "#            weights += layer.weights\n",
    "#        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveSequential:\n",
    "    # called when class object is connstructed i.e. NaiveSequential( <layers_passed_here>)\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        weights = []\n",
    "        for l in self.layers:\n",
    "            weights.append(l.weights)\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# model = NaiveSequential([\n",
    "#     NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),\n",
    "#     NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n",
    "# ])\n",
    "# assert len(model.weights) == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 256\n",
    "model = NaiveSequential([\n",
    "    NaiveDense(train_images.shape[1], num_nodes, tf.nn.relu),\n",
    "    NaiveDense(num_nodes, len(set(train_labels)), tf.nn.softmax),    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A batch generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class BatchGenerator:\n",
    "    def __init__(self, images, labels, batch_size=128):\n",
    "        assert len(images) == len(labels)\n",
    "        self.index = 0\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = math.ceil(len(images) / batch_size)\n",
    "\n",
    "    def next(self):\n",
    "        images = self.images[self.index : self.index + self.batch_size]\n",
    "        labels = self.labels[self.index : self.index + self.batch_size]\n",
    "        self.index += self.batch_size\n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 784)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_images.reshape(128,-1,784).shape\n",
    "batch_size = 128\n",
    "num_batches = int(train_images.shape[0]/batch_size)\n",
    "train_images_batches = train_images[:num_batches*batch_size].reshape(num_batches, batch_size, -1)\n",
    "train_images_batches.shape\n",
    "# train_images[num_batches*batch_size:].reshape[]\n",
    "\n",
    "# Note - if index exceeded, it falls back to the last index\n",
    "train_images[59990:61000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    def __init__(self, images, labels, batch_size=128):\n",
    "        assert len(images) == len(labels)\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    " \n",
    "        self.idx = 0\n",
    "        # math ceil implementation\n",
    "        self.num_batches = int( (self.images.shape[0]+batch_size-1)/batch_size )\n",
    "    \n",
    "    def next(self):\n",
    "        self.idx+=1\n",
    "        return self.images[(self.idx-1)*self.batch_size:self.idx*self.batch_size], self.labels[(self.idx-1)*self.batch_size:self.idx*self.batch_size]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Running one training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# def one_training_step(model, images_batch, labels_batch):\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         predictions = model(images_batch)\n",
    "#         per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "#             labels_batch, predictions)\n",
    "#         average_loss = tf.reduce_mean(per_sample_losses)\n",
    "#     gradients = tape.gradient(average_loss, model.weights)\n",
    "#     update_weights(gradients, model.weights)\n",
    "#     return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(model, images_batch, labels_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # print(\"before preds\")\n",
    "        preds = model(images_batch)\n",
    "        # print(\"after preds\")\n",
    "        # print(\"before losses_batch\")\n",
    "        losses_batch = tf.losses.sparse_categorical_crossentropy(labels_batch, preds)\n",
    "        # print(\"after losses_batch\")\n",
    "        loss = tf.reduce_mean(losses_batch)\n",
    "    grads = tape.gradient(loss, model.weights)\n",
    "    update_weights(grads, model.weights)\n",
    "    # update_wts(grads, model.weights)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# learning_rate = 1e-3\n",
    "\n",
    "# def update_weights(gradients, weights):\n",
    "#     for g, w in zip(gradients, weights):\n",
    "#         w.assign_sub(g * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.Variable.assign_sub?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE -modified the below code. Doesn't work with even the recommended tf v2.6 (by FChollet). Added for loop to iterate over a list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "\n",
    "def update_weights(grads, wts):\n",
    "    for g,w in zip(grads,wts):\n",
    "        # print( type(grads[0]) )\n",
    "        # print( type(wts[0]) )\n",
    "        # print( type(w[0]) )\n",
    "        # print( type(g[0]) )\n",
    "        \n",
    "        for g0,w0 in zip(g,w):\n",
    "            w0.assign_sub(lr*g0)\n",
    "        # w.assign_sub(lr*g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras import optimizers\n",
    "\n",
    "# optimizer = optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "# def update_weights(gradients, weights):\n",
    "#     optimizer.apply_gradients(zip(gradients, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=1e-3, beta_1=0.9, beta_2=.999)\n",
    "\n",
    "def update_wts(grads, wts):\n",
    "    optimizer.apply_gradients( zip(grads,wts) )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The full training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# def fit(model, images, labels, epochs, batch_size=128):\n",
    "#     for epoch_counter in range(epochs):\n",
    "#         print(f\"Epoch {epoch_counter}\")\n",
    "#         batch_generator = BatchGenerator(images, labels)\n",
    "#         for batch_counter in range(batch_generator.num_batches):\n",
    "#             images_batch, labels_batch = batch_generator.next()\n",
    "#             loss = one_training_step(model, images_batch, labels_batch)\n",
    "#             if batch_counter % 100 == 0:\n",
    "#                 print(f\"loss at batch {batch_counter}: {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, images, labels, epochs=5, batch_size=128):\n",
    "    for e in range(epochs):\n",
    "        batch_gen = BatchGenerator(images, labels)\n",
    "        for b in range(batch_gen.num_batches):\n",
    "            b_imgs, b_labels = batch_gen.next()\n",
    "            loss = training_step(model, b_imgs, b_labels)\n",
    "            if b%100 == 0:\n",
    "                print(f\"loss at batch number {b} = {loss:.2f}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at batch number 0 = 4.58\n",
      "loss at batch number 100 = 2.26\n",
      "loss at batch number 200 = 2.22\n",
      "loss at batch number 300 = 2.18\n",
      "loss at batch number 400 = 2.17\n",
      "loss at batch number 0 = 2.08\n",
      "loss at batch number 100 = 2.07\n",
      "loss at batch number 200 = 2.01\n",
      "loss at batch number 300 = 1.98\n",
      "loss at batch number 400 = 1.97\n",
      "loss at batch number 0 = 1.88\n",
      "loss at batch number 100 = 1.89\n",
      "loss at batch number 200 = 1.81\n",
      "loss at batch number 300 = 1.77\n",
      "loss at batch number 400 = 1.78\n",
      "loss at batch number 0 = 1.68\n",
      "loss at batch number 100 = 1.70\n",
      "loss at batch number 200 = 1.60\n",
      "loss at batch number 300 = 1.57\n",
      "loss at batch number 400 = 1.59\n",
      "loss at batch number 0 = 1.48\n",
      "loss at batch number 100 = 1.51\n",
      "loss at batch number 200 = 1.40\n",
      "loss at batch number 300 = 1.38\n",
      "loss at batch number 400 = 1.41\n",
      "loss at batch number 0 = 1.30\n",
      "loss at batch number 100 = 1.34\n",
      "loss at batch number 200 = 1.23\n",
      "loss at batch number 300 = 1.22\n",
      "loss at batch number 400 = 1.26\n",
      "loss at batch number 0 = 1.15\n",
      "loss at batch number 100 = 1.20\n",
      "loss at batch number 200 = 1.08\n",
      "loss at batch number 300 = 1.09\n",
      "loss at batch number 400 = 1.14\n",
      "loss at batch number 0 = 1.03\n",
      "loss at batch number 100 = 1.08\n",
      "loss at batch number 200 = 0.96\n",
      "loss at batch number 300 = 0.98\n",
      "loss at batch number 400 = 1.05\n",
      "loss at batch number 0 = 0.93\n",
      "loss at batch number 100 = 0.98\n",
      "loss at batch number 200 = 0.86\n",
      "loss at batch number 300 = 0.90\n",
      "loss at batch number 400 = 0.97\n",
      "loss at batch number 0 = 0.85\n",
      "loss at batch number 100 = 0.90\n",
      "loss at batch number 200 = 0.79\n",
      "loss at batch number 300 = 0.83\n",
      "loss at batch number 400 = 0.91\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "fit(model, train_images, train_labels, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.80\n"
     ]
    }
   ],
   "source": [
    "predictions = model(test_images)\n",
    "predictions = predictions.numpy()\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "matches = predicted_labels == test_labels\n",
    "print(f\"accuracy: {matches.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "accuracy = 80.04\n",
      "accuracy = 80.04\n"
     ]
    }
   ],
   "source": [
    "print(type(preds))\n",
    "preds_np = preds.numpy()\n",
    "preds_np\n",
    "preds_labels = np.argmax(preds, axis=1)\n",
    "print(\"accuracy = {}\".format( 100*(preds_labels==test_labels).mean() )  )\n",
    "\n",
    "# This is interesting - operationon variable can also be done in the print string -\n",
    "print(f\"accuracy = { 100*(preds_labels==test_labels).mean() }\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter02_mathematical-building-blocks.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py_3.7_tf_2.6",
   "language": "python",
   "name": "py_3.7_tf_2.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
